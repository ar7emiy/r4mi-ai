# r4mi-ai â€” Claude Code Build Instructions

## What This System Is

r4mi-ai is a **UI workflow observation and automation factory**. It watches human workers use existing software (in this case: a municipal permit processing system built on Chatwoot), silently detects repetitive patterns, then helps the worker collaboratively build, tune, and publish narrow AI agents that progressively take over their repetitive work.

The key properties of the system:

- **Workers never stop working** â€” the system observes passively and surfaces opportunities in a non-blocking tab
- **No automatic approvals** â€” the expert always confirms action sequences and knowledge sources before anything is published
- **Agent market with trust lifecycle** â€” agents start supervised, earn autonomy through successful runs, and deprecate when stale
- **Contribution tracking** â€” when an existing agent from another user is tuned and forked, contribution scores are split by code delta

-----

## System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FRONTEND (React 19 + Vite)               â”‚
â”‚  Chatwoot-embedded sidebar  â”‚  Tab progression bar          â”‚
â”‚  Source highlight overlay   â”‚  Agent demo playback          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚ WebSocket (AG-UI SSE)       â”‚ REST
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  BACKEND (FastAPI 0.133.1)                   â”‚
â”‚  /observe   â€” receives UI event stream from browser ext     â”‚
â”‚  /patterns  â€” pattern detection state machine               â”‚
â”‚  /agents    â€” agent market CRUD + trust scoring             â”‚
â”‚  /session   â€” replay + confirmation flow                    â”‚
â”‚  /sse       â€” server-sent events to frontend                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               AI LAYER (google-adk + google-genai)          â”‚
â”‚  ObserverAgent    â€” watches event stream, extracts patterns  â”‚
â”‚  SpecBuilderAgent â€” converts confirmed trace â†’ agent spec   â”‚
â”‚  MarketMatcher    â€” semantic search over agentverse         â”‚
â”‚  NarrowAgent      â€” executes a published workflow spec      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

-----

## Package Versions (Confirmed Latest â€” Feb 27, 2026)

### Python Backend

```
python>=3.12
fastapi==0.133.1
uvicorn[standard]==0.34.0
google-genai>=1.0.0          # New unified SDK â€” NOT google-generativeai (legacy)
google-adk>=1.0.0            # Agent Development Kit, bi-weekly releases
pydantic>=2.12.0
python-dotenv>=1.0.0
sse-starlette>=2.1.0
sqlmodel>=0.0.21             # SQLite persistence for agent market
httpx>=0.28.0
pytest>=8.3.0
pytest-asyncio>=0.25.0
```

### Frontend

```json
{
  "react": "^19.2.4",
  "typescript": "^5.9.3",
  "vite": "^7.3.1",
  "@vitejs/plugin-react": "^5.1.4",
  "tailwindcss": "^4.2.1",
  "shadcn-ui": "latest",
  "zustand": "^5.0.11",
  "@tanstack/react-query": "^5.90.21",
  "mermaid": "^11.12.3"
}
```

### Key SDK Notes

- Use `from google import genai` â€” **not** `import google.generativeai`
- Default model: `gemini-2.5-flash`
- ADK agent pattern: `from google.adk.agents import Agent`
- ADK requires Python 3.10+ â€” use 3.12

-----

## System Diagram (UML Activity â€” 3 Swimlanes)

This diagram must be rendered in the frontend using Mermaid. Include it at `/frontend/src/assets/system-diagram.mermaid`.

```mermaid
flowchart TD
    START([â—])

    subgraph TECH["swimlane: ðŸ‘¤ Permit Tech"]
        T1["Works permit normally\nacross multiple screens"]
        T2["Receives tab notification\nðŸ”” Optimization Opportunity"]
        T3["Opens notification\non own time"]
        T4["Watches session replay"]
        T5{{"Confirm\naction sequence?"}}
        T6["Corrects sequence"]
        T7{{"Confirm\nknowledge sources?"}}
        T8["Corrects sources\ne.g. 'use PDF not wiki'"]
        T9A["Watches agent\ndemo live on screen"]
        T10{{"Agent matches\nmy workflow?"}}
        T11["Tunes agent\nin collaboration"]
        T12["Continues working\nwith agents in tab bar"]
        T13{{"Exception\nor low confidence?"}}
        T14["Reviews exception\nmanually"]
    end

    subgraph R4MI["swimlane: ðŸ¤– r4mi-ai Observer"]
        R1["Observes UI events\n+ backend calls silently"]
        R2["On screen switch:\nhighlights unstructured\nsource being read"]
        R3["Logs full action\ntrace + sources"]
        R4{{"Repetitive pattern\ndetected?"}}
        R5["Replays every move\nstep by step on screen"]
        R6["Highlights extracted\nknowledge sources\nwith confidence %"]
        R7["Queries Agentverse\nfor similar narrow agent"]
        R8{{"Match\nfound?"}}
        R9A["Loads existing agent\nfor live demo"]
        R9B["Builds new agent\nfrom confirmed trace"]
        R10A["Applies tuning delta\nfrom Tech input"]
        R11["Runs agent in background\non new permits"]
        R12["Highlights sources\non each screen switch"]
        R13["Flags low confidence\nor exception"]
    end

    subgraph AGENTVERSE["swimlane: ðŸŒ Narrow-Agentverse"]
        A1{{"Similar agent\nexists?"}}
        A2["Returns agent +\ncontribution metadata\n(author, score %)"]
        A3["Publishes tuned fork\nlogs contribution split"]
        A4["Publishes new agent\n100% contribution\n(Supervised mode)"]
        A5["Agent active\nin Tech tab bar"]
        A6["Increments trust score\nper successful run"]
    end

    START --> T1
    T1 --> R1
    R1 --> R2
    R2 -->|"each screen switch"| R2
    R2 --> R3
    R3 --> R4
    R4 -->|"No"| T1
    R4 -->|"Yes"| T2
    T2 --> T3
    T3 --> R5
    R5 --> T4
    T4 --> T5
    T5 -->|"No"| T6
    T6 --> R5
    T5 -->|"Yes"| R6
    R6 --> T7
    T7 -->|"No"| T8
    T8 --> R6
    T7 -->|"Yes"| R7
    R7 --> A1
    A1 -->|"Yes"| A2
    A1 -->|"No"| R9B
    A2 --> R9A
    R9A --> T9A
    T9A --> T10
    T10 -->|"No"| T11
    T11 --> R10A
    R10A --> A3
    T10 -->|"Yes"| A3
    A3 --> A5
    R9B --> A4
    A4 --> A5
    A5 --> T12
    T12 --> R11
    R11 --> R12
    R12 --> R13
    R13 -->|"All good"| A6
    A6 --> T12
    R13 -->|"Exception"| T13
    T13 -->|"Yes"| T14
    T14 --> R1
    T13 -->|"No"| A6
```

-----

## Project Structure

```
r4mi-ai/
â”œâ”€â”€ CLAUDE.md                        â† this file
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env.example
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                      â† FastAPI app entrypoint
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ observer_agent.py        â† ADK agent: watches UI event stream
â”‚   â”‚   â”œâ”€â”€ spec_builder_agent.py    â† ADK agent: trace â†’ spec
â”‚   â”‚   â”œâ”€â”€ market_matcher.py        â† semantic similarity search over agentverse
â”‚   â”‚   â””â”€â”€ narrow_agent.py         â† ADK agent: executes a published spec
â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”œâ”€â”€ observe.py               â† POST /observe â€” receives browser events
â”‚   â”‚   â”œâ”€â”€ patterns.py              â† GET /patterns â€” state machine status
â”‚   â”‚   â”œâ”€â”€ agents.py                â† CRUD for agent market
â”‚   â”‚   â”œâ”€â”€ session.py               â† replay, confirmation, tuning endpoints
â”‚   â”‚   â””â”€â”€ sse.py                   â† SSE stream to frontend
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ event.py                 â† UIEvent, ActionTrace, KnowledgeSource
â”‚   â”‚   â”œâ”€â”€ agent_spec.py            â† NarrowAgentSpec, TrustLevel, Contribution
â”‚   â”‚   â””â”€â”€ session.py               â† ObservationSession, ReplayFrame
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ pattern_detector.py      â† 10-stage state machine
â”‚   â”‚   â”œâ”€â”€ trust_engine.py          â† supervised â†’ autonomous promotion logic
â”‚   â”‚   â”œâ”€â”€ contribution_tracker.py  â† code delta â†’ attribution split
â”‚   â”‚   â””â”€â”€ knowledge_extractor.py   â† unstructured source identification + confidence
â”‚   â””â”€â”€ db.py                        â† SQLModel + SQLite setup
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ main.tsx
â”‚   â”‚   â”œâ”€â”€ App.tsx
â”‚   â”‚   â”œâ”€â”€ assets/
â”‚   â”‚   â”‚   â””â”€â”€ system-diagram.mermaid   â† embed the UML diagram above
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ TabProgressionBar.tsx    â† persistent agent task bar at bottom
â”‚   â”‚   â”‚   â”œâ”€â”€ OptimizationTab.tsx      â† non-blocking notification tab
â”‚   â”‚   â”‚   â”œâ”€â”€ SessionReplay.tsx        â† step-by-step replay of user actions
â”‚   â”‚   â”‚   â”œâ”€â”€ SourceHighlight.tsx      â† overlay that highlights unstructured sources
â”‚   â”‚   â”‚   â”œâ”€â”€ AgentDemo.tsx            â† live agent execution demo on screen
â”‚   â”‚   â”‚   â”œâ”€â”€ TuningPanel.tsx          â† collaborative tuning with diff view
â”‚   â”‚   â”‚   â”œâ”€â”€ AgentMarket.tsx          â† browse agentverse, see trust/contributions
â”‚   â”‚   â”‚   â””â”€â”€ SystemDiagram.tsx        â† renders system-diagram.mermaid via mermaid.js
â”‚   â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”‚   â”œâ”€â”€ useSSE.ts               â† connects to /sse, drives UI updates
â”‚   â”‚   â”‚   â”œâ”€â”€ useAgentMarket.ts
â”‚   â”‚   â”‚   â””â”€â”€ useReplay.ts
â”‚   â”‚   â””â”€â”€ store/
â”‚   â”‚       â””â”€â”€ r4mi.store.ts           â† Zustand global state
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.ts
â”‚
â””â”€â”€ chatwoot/
    â””â”€â”€ docker-compose.yml            â† Chatwoot instance for demo environment
```

-----

## Core Data Models

### UIEvent (what the browser extension sends)

```python
class UIEvent(BaseModel):
    session_id: str
    user_id: str
    timestamp: datetime
    event_type: str          # "click" | "navigate" | "input" | "screen_switch"
    screen_name: str         # e.g. "GIS_SYSTEM" | "CODE_ENFORCEMENT" | "POLICY_WIKI"
    element_selector: str
    element_value: Optional[str]
    backend_call: Optional[dict]    # captured XHR/fetch payload
    screenshot_b64: Optional[str]   # for Gemini Vision analysis
```

### NarrowAgentSpec (what gets published to the market)

```python
class TrustLevel(str, Enum):
    SUPERVISED = "supervised"
    AUTONOMOUS = "autonomous"
    STALE = "stale"

class Contribution(BaseModel):
    user_id: str
    score: float             # 0.0â€“1.0, proportional to code delta

class NarrowAgentSpec(SQLModel, table=True):
    id: str = Field(default_factory=lambda: str(uuid4()))
    name: str
    description: str
    trigger_pattern: dict    # what pattern activates this agent
    action_sequence: list    # ordered list of UI actions to replay
    knowledge_sources: list  # list of {screen, selector, confidence}
    trust_level: TrustLevel = TrustLevel.SUPERVISED
    successful_runs: int = 0
    failed_runs: int = 0
    contributions: list[Contribution] = []
    created_at: datetime
    updated_at: datetime
```

-----

## Key Behaviours to Implement

### 1. Passive Observation (ObserverAgent)

- Browser extension streams `UIEvent` objects to `POST /observe`
- ObserverAgent uses Gemini Vision on screenshots to identify unstructured text regions
- Pattern detector runs a 10-stage state machine to identify repetition across sessions
- When pattern confidence > threshold: emit SSE event `OPTIMIZATION_OPPORTUNITY` to frontend

### 2. Optimization Tab (Non-blocking)

- Tab appears in the `TabProgressionBar` â€” glows but does not interrupt current work
- User opens it when ready â€” the system waited
- Shows: "I noticed you do this 3 times. Watch the replay and confirm."

### 3. Session Replay + Confirmation (2 steps)

**Step 1 â€” Action Sequence:**

- Replay every captured UIEvent step by step at 0.5x speed
- Each step highlights the element interacted with
- User confirms or scrubs back and corrects

**Step 2 â€” Knowledge Sources:**

- Highlights each unstructured region Gemini identified as a knowledge source
- Shows confidence % per source
- User confirms or replaces (e.g., "use this PDF instead of the wiki")

### 4. Agentverse Match

- After confirmation, MarketMatcher runs semantic similarity over published specs
- If match found (cosine similarity > 0.85): demo existing agent live on screen
- User can accept as-is, tune it (diff is tracked for contribution split), or reject
- If no match: SpecBuilderAgent builds a new spec from confirmed trace

### 5. Trust Engine

```
SUPERVISED â†’ AUTONOMOUS: when successful_runs >= 10 AND failed_runs/total < 0.05
AUTONOMOUS â†’ STALE: when agent fails on a pattern it previously handled
             OR when policy docs referenced have changed (hash comparison)
STALE â†’ re-observation: route next matching permit back to human, restart cycle
```

### 6. Tab Progression Bar

- Persistent bottom bar showing all active agents for the current session
- Each agent shows: name, status indicator (running/idle/flagging), last run result
- Agents run in background â€” user only pulled in for exceptions or low confidence

### 7. Screen-Switch Highlighting

- On every `screen_switch` event, SourceHighlight overlay fires
- Gemini identifies unstructured regions (freetext fields, notes columns, policy paragraphs)
- Highlights them with a soft glow + tooltip: "r4mi-ai focusing here (confidence: 84%)"
- This happens both during observation AND during agent execution

-----

## Gemini / ADK Usage

### ObserverAgent

```python
from google.adk.agents import Agent
from google import genai

observer_agent = Agent(
    name="observer_agent",
    model="gemini-2.5-flash",
    instruction="""
    You receive a stream of UI events from a permit processing worker.
    Your job is to:
    1. Identify repetitive decision patterns across sessions
    2. Extract which unstructured text regions the worker consulted
    3. Assign confidence scores to each knowledge source
    4. Flag when a pattern is mature enough to propose automation
    """,
    tools=[detect_pattern_tool, extract_knowledge_sources_tool]
)
```

### SpecBuilderAgent

```python
spec_builder_agent = Agent(
    name="spec_builder_agent",
    model="gemini-2.5-flash",
    instruction="""
    Given a confirmed action trace and confirmed knowledge sources,
    generate a NarrowAgentSpec that captures:
    - The trigger condition (what incoming data activates this agent)
    - The ordered action sequence
    - The knowledge sources to consult and how to interpret them
    - The decision logic (as a human-readable rule)
    Output as JSON matching the NarrowAgentSpec schema.
    """,
)
```

-----

## Demo Scenario: Municipal Permit Processing

The demo environment is a Chatwoot instance configured to simulate a permit office:

- **Inbox:** Incoming permit applications (simulated as conversations)
- **Custom attributes:** Parcel ID, Zone, Violation history flag, Sewer capacity status
- **Internal notes:** Agent decision log, policy references

**3 simulated permit types for the demo:**

1. **Fence variance, Zone R-2, no violations** â†’ clean approval path
1. **ADU addition, mixed zone, prior violation** â†’ requires manual check + escalation
1. **Commercial signage** â†’ triggers policy wiki lookup + setback calculation

The demo shows the system going from empty agentverse â†’ first agent published â†’ same permit type handled autonomously â†’ stale detection when zone classification changes.

-----

## Environment Variables

```bash
# .env.example
GEMINI_API_KEY=your_key_here
GOOGLE_GENAI_USE_VERTEXAI=false     # set true for Vertex AI
DATABASE_URL=sqlite:///./r4mi.db
CHATWOOT_API_URL=http://localhost:3000
CHATWOOT_API_KEY=your_chatwoot_key
PATTERN_CONFIDENCE_THRESHOLD=0.75
AGENTVERSE_MATCH_THRESHOLD=0.85
TRUST_PROMOTION_MIN_RUNS=10
TRUST_PROMOTION_MAX_FAILURE_RATE=0.05
```

-----

## Build Order for Claude Code

Work in this sequence â€” each step is independently testable:

1. **Backend scaffolding** â€” FastAPI app, SQLModel DB, all routers returning stubs
1. **Data models** â€” UIEvent, NarrowAgentSpec, ObservationSession with full Pydantic validation
1. **SSE layer** â€” `/sse` endpoint, client reconnect logic, event typing
1. **ObserverAgent** â€” ADK agent wired to Gemini, pattern state machine, confidence scoring
1. **Replay + Confirmation endpoints** â€” session storage, step-by-step replay frames, 2-step confirm flow
1. **SpecBuilderAgent** â€” trace â†’ spec generation, JSON schema enforcement
1. **MarketMatcher** â€” cosine similarity over spec embeddings using Gemini embed API
1. **Trust Engine** â€” promotion logic, staleness detection, re-observation routing
1. **Frontend: TabProgressionBar + OptimizationTab** â€” Zustand store, SSE hook
1. **Frontend: SessionReplay + SourceHighlight** â€” replay playback, Gemini highlight overlay
1. **Frontend: AgentDemo + TuningPanel** â€” live demo, diff-based contribution tracking
1. **Frontend: AgentMarket + SystemDiagram** â€” market browser, Mermaid diagram render
1. **Chatwoot integration** â€” AgentBot webhook, custom attribute read/write
1. **Demo data + Docker Compose** â€” seed script, multi-container setup

-----

## Notes for Claude Code

- Use `async/await` throughout â€” both FastAPI and ADK are async-native
- SSE events must be typed â€” define an `SSEEventType` enum and use it everywhere
- The frontend never polls â€” everything is driven by SSE
- Mermaid diagram renders client-side via `mermaid.initialize()` â€” import from npm
- Gemini Vision calls are expensive â€” cache screenshot analysis per session+screen, invalidate on navigation
- The browser extension is out of scope for the hackathon â€” simulate it with a test script that POSTs mock UIEvent sequences to `/observe`
- All agent specs are versioned â€” never mutate a published spec, always fork
